{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "width, height = (48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.load(\"./Train.npy\")\n",
    "y=np.load(\"./Label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_val=x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=(x-mean_val)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.2328843 ],\n",
       "         [-0.19366862],\n",
       "         [-0.18582548],\n",
       "         ...,\n",
       "         [-0.30347255],\n",
       "         [-0.33876666],\n",
       "         [-0.3466098 ]],\n",
       "\n",
       "        [[-0.25249216],\n",
       "         [-0.26817843],\n",
       "         [-0.27994314],\n",
       "         ...,\n",
       "         [-0.28778628],\n",
       "         [-0.30347255],\n",
       "         [-0.3348451 ]],\n",
       "\n",
       "        [[-0.3113157 ],\n",
       "         [-0.33876666],\n",
       "         [-0.2956294 ],\n",
       "         ...,\n",
       "         [-0.31523725],\n",
       "         [-0.28778628],\n",
       "         [-0.3230804 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.15053137],\n",
       "         [-0.25249216],\n",
       "         [-0.34268823],\n",
       "         ...,\n",
       "         [-0.22504117],\n",
       "         [-0.28778628],\n",
       "         [-0.33876666]],\n",
       "\n",
       "        [[-0.20543332],\n",
       "         [-0.18582548],\n",
       "         [-0.19759019],\n",
       "         ...,\n",
       "         [-0.0956294 ],\n",
       "         [-0.2328843 ],\n",
       "         [-0.32700196]],\n",
       "\n",
       "        [[-0.20543332],\n",
       "         [-0.22504117],\n",
       "         [-0.17798235],\n",
       "         ...,\n",
       "         [-0.09170783],\n",
       "         [-0.07994313],\n",
       "         [-0.18582548]]],\n",
       "\n",
       "\n",
       "       [[[ 0.08476275],\n",
       "         [ 0.08084118],\n",
       "         [ 0.06907648],\n",
       "         ...,\n",
       "         [-0.00151176],\n",
       "         [ 0.0416255 ],\n",
       "         [-0.03680588]],\n",
       "\n",
       "        [[ 0.08476275],\n",
       "         [ 0.07691962],\n",
       "         [ 0.07691962],\n",
       "         ...,\n",
       "         [-0.02896274],\n",
       "         [ 0.04554707],\n",
       "         [ 0.02986079]],\n",
       "\n",
       "        [[ 0.08476275],\n",
       "         [ 0.08476275],\n",
       "         [ 0.10437059],\n",
       "         ...,\n",
       "         [-0.07994313],\n",
       "         [-0.02504117],\n",
       "         [ 0.06515491]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2298608 ],\n",
       "         [ 0.2298608 ],\n",
       "         [-0.03288431],\n",
       "         ...,\n",
       "         [ 0.21809609],\n",
       "         [ 0.21809609],\n",
       "         [ 0.22201766]],\n",
       "\n",
       "        [[ 0.2298608 ],\n",
       "         [ 0.22593923],\n",
       "         [ 0.26123333],\n",
       "         ...,\n",
       "         [ 0.22201766],\n",
       "         [ 0.20633139],\n",
       "         [ 0.22593923]],\n",
       "\n",
       "        [[ 0.22201766],\n",
       "         [ 0.21417452],\n",
       "         [ 0.21809609],\n",
       "         ...,\n",
       "         [ 0.24946864],\n",
       "         [ 0.21025296],\n",
       "         [ 0.21417452]]],\n",
       "\n",
       "\n",
       "       [[[ 0.39848825],\n",
       "         [ 0.32397845],\n",
       "         [ 0.10437059],\n",
       "         ...,\n",
       "         [-0.3348451 ],\n",
       "         [-0.40151176],\n",
       "         [-0.444649  ]],\n",
       "\n",
       "        [[ 0.39064512],\n",
       "         [ 0.1788804 ],\n",
       "         [ 0.07299805],\n",
       "         ...,\n",
       "         [-0.40151176],\n",
       "         [-0.3701392 ],\n",
       "         [-0.40151176]],\n",
       "\n",
       "        [[ 0.3318216 ],\n",
       "         [ 0.10437059],\n",
       "         [ 0.10829216],\n",
       "         ...,\n",
       "         [-0.3975902 ],\n",
       "         [-0.4211196 ],\n",
       "         [-0.3975902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.43770394],\n",
       "         [ 0.4533902 ],\n",
       "         [ 0.47299805],\n",
       "         ...,\n",
       "         [-0.2838647 ],\n",
       "         [-0.11131568],\n",
       "         [ 0.06515491]],\n",
       "\n",
       "        [[ 0.45731178],\n",
       "         [ 0.47299805],\n",
       "         [ 0.4808412 ],\n",
       "         ...,\n",
       "         [-0.20151176],\n",
       "         [-0.0956294 ],\n",
       "         [ 0.1279    ]],\n",
       "\n",
       "        [[ 0.47299805],\n",
       "         [ 0.47691962],\n",
       "         [ 0.47299805],\n",
       "         ...,\n",
       "         [-0.16229607],\n",
       "         [-0.07602156],\n",
       "         [ 0.08868432]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-0.44072744],\n",
       "         [-0.44072744],\n",
       "         [-0.444649  ],\n",
       "         ...,\n",
       "         [-0.18190391],\n",
       "         [-0.06033529],\n",
       "         [ 0.4533902 ]],\n",
       "\n",
       "        [[-0.43680587],\n",
       "         [-0.44072744],\n",
       "         [-0.444649  ],\n",
       "         ...,\n",
       "         [-0.09955097],\n",
       "         [ 0.02593922],\n",
       "         [ 0.48476276]],\n",
       "\n",
       "        [[-0.4328843 ],\n",
       "         [-0.444649  ],\n",
       "         [-0.44072744],\n",
       "         ...,\n",
       "         [-0.00543333],\n",
       "         [ 0.08868432],\n",
       "         [ 0.4926059 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.49170783],\n",
       "         [-0.42504117],\n",
       "         [-0.32700196],\n",
       "         ...,\n",
       "         [ 0.22201766],\n",
       "         [ 0.19848825],\n",
       "         [ 0.22593923]],\n",
       "\n",
       "        [[-0.48778626],\n",
       "         [-0.44072744],\n",
       "         [-0.3466098 ],\n",
       "         ...,\n",
       "         [ 0.18672353],\n",
       "         [ 0.16711569],\n",
       "         [ 0.18280196]],\n",
       "\n",
       "        [[-0.42896274],\n",
       "         [-0.44857058],\n",
       "         [-0.4211196 ],\n",
       "         ...,\n",
       "         [ 0.09652746],\n",
       "         [ 0.01417452],\n",
       "         [-0.06425685]]],\n",
       "\n",
       "\n",
       "       [[[-0.38974705],\n",
       "         [-0.3975902 ],\n",
       "         [-0.3975902 ],\n",
       "         ...,\n",
       "         [-0.2721    ],\n",
       "         [-0.3113157 ],\n",
       "         [-0.3348451 ]],\n",
       "\n",
       "        [[-0.38974705],\n",
       "         [-0.40151176],\n",
       "         [-0.3975902 ],\n",
       "         ...,\n",
       "         [-0.25641373],\n",
       "         [-0.30347255],\n",
       "         [-0.35053137]],\n",
       "\n",
       "        [[-0.38582548],\n",
       "         [-0.3975902 ],\n",
       "         [-0.38974705],\n",
       "         ...,\n",
       "         [-0.26817843],\n",
       "         [-0.2956294 ],\n",
       "         [-0.36229607]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.09955097],\n",
       "         [-0.07994313],\n",
       "         [-0.07602156],\n",
       "         ...,\n",
       "         [-0.3701392 ],\n",
       "         [-0.38974705],\n",
       "         [-0.38974705]],\n",
       "\n",
       "        [[-0.10739411],\n",
       "         [-0.0956294 ],\n",
       "         [-0.0838647 ],\n",
       "         ...,\n",
       "         [-0.3701392 ],\n",
       "         [-0.38582548],\n",
       "         [-0.39366862]],\n",
       "\n",
       "        [[-0.14268823],\n",
       "         [-0.13092352],\n",
       "         [-0.11523725],\n",
       "         ...,\n",
       "         [-0.3701392 ],\n",
       "         [-0.38974705],\n",
       "         [-0.3975902 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.4328843 ],\n",
       "         [-0.45641372],\n",
       "         [-0.45249215],\n",
       "         ...,\n",
       "         [-0.0838647 ],\n",
       "         [-0.1348451 ],\n",
       "         [-0.17013921]],\n",
       "\n",
       "        [[-0.444649  ],\n",
       "         [-0.44072744],\n",
       "         [-0.44857058],\n",
       "         ...,\n",
       "         [-0.0956294 ],\n",
       "         [-0.13876666],\n",
       "         [-0.15445293]],\n",
       "\n",
       "        [[-0.46817842],\n",
       "         [-0.4721    ],\n",
       "         [-0.46817842],\n",
       "         ...,\n",
       "         [-0.11131568],\n",
       "         [-0.14268823],\n",
       "         [-0.1348451 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.43680587],\n",
       "         [-0.45249215],\n",
       "         [-0.444649  ],\n",
       "         ...,\n",
       "         [-0.29170784],\n",
       "         [-0.25641373],\n",
       "         [-0.1348451 ]],\n",
       "\n",
       "        [[-0.44857058],\n",
       "         [-0.44857058],\n",
       "         [-0.45641372],\n",
       "         ...,\n",
       "         [-0.02504117],\n",
       "         [ 0.16319412],\n",
       "         [ 0.24554707]],\n",
       "\n",
       "        [[-0.444649  ],\n",
       "         [-0.45249215],\n",
       "         [-0.45641372],\n",
       "         ...,\n",
       "         [ 0.23378237],\n",
       "         [ 0.27299803],\n",
       "         [ 0.28084117]]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=45)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29068 samples, validate on 3230 samples\n",
      "Epoch 1/100\n",
      "  448/29068 [..............................] - ETA: 12:09 - loss: 4.5101 - accuracy: 0.1629"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-6177331c6d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m           shuffle=True)\n\u001b[0m",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss=['categorical_crossentropy'],\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "model.fit(np.array(X_train), np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_valid), np.array(y_valid)),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
